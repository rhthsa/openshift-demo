
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>OpenShift state backup with etcd snapshot Â· OpenShift Demo</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="Red Hat Thailand SA">
        
        
    
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search-plus/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-mermaid-gb3/mermaid/mermaid.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    


    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="infrastructure-taint-and-toleration.html" />
    
    
    <link rel="prev" href="infrastructure-networking.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" >
            
                <span>
            
                    
                    Infrastructure
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="infrastructure-authentication-providers.html">
            
                <a href="infrastructure-authentication-providers.html">
            
                    
                    OpenShift Authentication Providers with AD
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="infrastructure-infra-nodes.html">
            
                <a href="infrastructure-infra-nodes.html">
            
                    
                    OpenShift MachineSet and Infrastructure Nodes
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="infrastructure-monitoring-alerts.html">
            
                <a href="infrastructure-monitoring-alerts.html">
            
                    
                    OpenShift Platform Monitoring and Alert
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="infrastructure-cluster-logging.html">
            
                <a href="infrastructure-cluster-logging.html">
            
                    
                    OpenShift Cluster Logging
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="infrastructure-networking.html">
            
                <a href="infrastructure-networking.html">
            
                    
                    OpenShift Networking
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.2.6" data-path="infrastructure-backup-etcd.html">
            
                <a href="infrastructure-backup-etcd.html">
            
                    
                    OpenShift state backup with etcd snapshot
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7" data-path="infrastructure-taint-and-toleration.html">
            
                <a href="infrastructure-taint-and-toleration.html">
            
                    
                    Pod Taint and Toleration
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.8" data-path="assign-pod-to-node.html">
            
                <a href="assign-pod-to-node.html">
            
                    
                    Assign pod to node
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.9" data-path="custom-roles.html">
            
                <a href="custom-roles.html">
            
                    
                    Custom Roles and Service Account
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.10" data-path="custom-alert.html">
            
                <a href="custom-alert.html">
            
                    
                    Custom Alert
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.11" data-path="compliance-operator.html">
            
                <a href="compliance-operator.html">
            
                    
                    Compliance
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" >
            
                <span>
            
                    
                    Multi-cluster Management with Advanced Cluster Management (RHACM)
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="acm-application-management.html">
            
                <a href="acm-application-management.html">
            
                    
                    Application Manageement
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="acm-hibernate.html">
            
                <a href="acm-hibernate.html">
            
                    
                    Cost saving with hibernating OpenShift
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" >
            
                <span>
            
                    
                    Advanced Cluster Security for Kubernetes
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="acs.html">
            
                <a href="acs.html">
            
                    
                    ACS
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" >
            
                <span>
            
                    
                    Applications
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="build-with-dev-console.html">
            
                <a href="build-with-dev-console.html">
            
                    
                    Developer Console
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="build-with-oc.html">
            
                <a href="build-with-oc.html">
            
                    
                    Application Build & Deployment with oc
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3" data-path="build-with-odo.html">
            
                <a href="build-with-odo.html">
            
                    
                    Application Build & Deployment with odo
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.4" data-path="helm.html">
            
                <a href="helm.html">
            
                    
                    Application Deployment with Helm
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.5" data-path="imagestreams.html">
            
                <a href="imagestreams.html">
            
                    
                    Image Streams
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.6" data-path="openshift-route.html">
            
                <a href="openshift-route.html">
            
                    
                    OpenShift Route
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.7" data-path="hpa.html">
            
                <a href="hpa.html">
            
                    
                    Horizontal Pod Autoscaler
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.8" data-path="health.html">
            
                <a href="health.html">
            
                    
                    Health Check
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.9" data-path="kustomize.html">
            
                <a href="kustomize.html">
            
                    
                    Kustomize
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.10" data-path="application-metrics.html">
            
                <a href="application-metrics.html">
            
                    
                    User Workload Monitoring
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.11" data-path="ci-cd-with-jenkins.html">
            
                <a href="ci-cd-with-jenkins.html">
            
                    
                    CI/CD with Jenkins
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.12" data-path="ci-cd.html">
            
                <a href="ci-cd.html">
            
                    
                    CI/CD with Azure DevOps
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.13" data-path="eap-on-ocp.html">
            
                <a href="eap-on-ocp.html">
            
                    
                    EAP on OpenShift
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" >
            
                <span>
            
                    
                    Additional Features
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="gitops.html">
            
                <a href="gitops.html">
            
                    
                    OpenShift GitOps
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="openshift-service-mesh.html">
            
                <a href="openshift-service-mesh.html">
            
                    
                    OpenShift Service Mesh
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.3" data-path="KEDA.html">
            
                <a href="KEDA.html">
            
                    
                    KEDA
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >OpenShift state backup with etcd snapshot</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div class="search-plus" id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="infrastructure-basic">Infrastructure Basic</h1>
<!-- TOC -->
<ul>
<li><a href="#infrastructure-basic">Infrastructure Basic</a><ul>
<li><a href="#prerequisites">Prerequisites</a></li>
<li><a href="#backup-etcd">Backup etcd</a><ul>
<li><a href="#backing-up-etcd-data">Backing up etcd data</a></li>
</ul>
</li>
<li><a href="#backup-etcd-with-cron-job">Backup etcd with cron job</a><ul>
<li><a href="#restoring-to-a-previous-cluster-state">Restoring to a previous cluster state</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<!-- /TOC -->
<h2 id="prerequisites">Prerequisites</h2>
<ul>
<li>OpenShift 4.6 on VMware 6.7 U3+ or 7.0</li>
<li>VMware Cloud Native Storage to support CNS CSI</li>
<li>OpenShift installer<ul>
<li>Node subnet with DHCP pool</li>
<li>DNS</li>
<li>NTP</li>
</ul>
</li>
</ul>
<h2 id="backup-etcd">Backup etcd</h2>
<p>etcd is the key-value store for OpenShift Container Platform, which persists the state of all resource objects.</p>
<p>Back up your cluster&#x2019;s etcd data regularly and store in a secure location ideally outside the OpenShift Container Platform environment.</p>
<p>After you have an etcd backup, you can restore to a previous cluster state.</p>
<h3 id="backing-up-etcd-data">Backing up etcd data</h3>
<p>Follow these steps to back up etcd data by creating an etcd snapshot and backing up the resources for the static pods. This backup can be saved and used at a later time if you need to restore etcd.</p>
<p>Prerequisites</p>
<ul>
<li>You have access to the cluster as a user with the cluster-admin role.</li>
<li>You have checked whether the cluster-wide proxy is enabled.</li>
</ul>
<p>Procedure</p>
<ul>
<li><p>Start a debug session for a master node:</p>
<pre><code class="lang-bash">oc debug node/&lt;node_name&gt;
</code></pre>
</li>
<li><p>Change your root directory to the host:</p>
<pre><code class="lang-bash">chroot /host
</code></pre>
</li>
<li><p>If the cluster-wide proxy is enabled, be sure that you have exported the <code>NO_PROXY</code>, <code>HTTP_PROXY</code>, and <code>HTTPS_PROXY</code> environment variables.</p>
</li>
<li><p>Run the cluster-backup.sh script and pass in the location to save the backup to.</p>
<pre><code class="lang-bash">/usr/local/bin/cluster-backup.sh /home/core/assets/backup
</code></pre>
<p>Example script output</p>
<pre><code class="lang-bash">1bf371f1b5a483927cd01bb593b0e12cff406eb8d7d0acf4ab079c36a0abd3f7
etcdctl version: 3.3.18
API version: 3.3
found latest kube-apiserver-pod: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-7
found latest kube-controller-manager-pod: /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-8
found latest kube-scheduler-pod: /etc/kubernetes/static-pod-resources/kube-scheduler-pod-6
found latest etcd-pod: /etc/kubernetes/static-pod-resources/etcd-pod-2
Snapshot saved at /home/core/assets/backup/snapshot_2020-03-18_220218.db
snapshot db and kube resources are successfully saved to /home/core/assets/backup
</code></pre>
<p>In this example, two files are created in the /home/core/assets/backup/ directory on the master host:</p>
<ul>
<li>snapshot_<datetimestamp>.db: This file is the etcd snapshot.</datetimestamp></li>
<li>static<em>kuberesources</em><datetimestamp>.tar.gz: This file contains the resources for the static pods. If etcd encryption is enabled, it also contains the encryption keys for the etcd snapshot.</datetimestamp></li>
</ul>
</li>
</ul>
<h2 id="backup-etcd-with-cron-job">Backup etcd with cron job</h2>
<p>Procedures:</p>
<ul>
<li><p>Set your sftp target, username and password</p>
<pre><code class="lang-bash">sftp_target=198.18.134.150
sftp_user=&quot;root&quot;
sftp_pass=&quot;b1ndP^ssword&quot;
</code></pre>
</li>
<li><p>Create a backup script</p>
<pre><code class="lang-bash">cat &lt;&lt; EOF &gt; etcd-backup-on-debug-pod.sh
#!/bin/sh

echo &quot;chroot to /host&quot;
chroot /host /bin/sh &lt;&lt; EOT

echo &quot;start cluster-backup.sh&quot;
/usr/local/bin/cluster-backup.sh /home/core/assets/backup

echo &quot;sftp backup files to sftp target&quot;
curl --insecure --user $sftp_user:$sftp_pass -T /home/core/assets/backup/snapshot*.db sftp://$sftp_target/root/backup/
curl --insecure --user $sftp_user:$sftp_pass -T /home/core/assets/backup/static*.tar.gz sftp://$sftp_target/root/backup/

echo &quot;remove local backup files&quot;
rm -f /home/core/assets/backup/*

EOT

EOF

chmod +x etcd-backup-on-debug-pod.sh
</code></pre>
</li>
<li><p>Create etcd backup namespace</p>
<pre><code class="lang-yaml">cat &lt;&lt; EOF | oc apply -f -
kind: Project
apiVersion: project.openshift.io/v1
metadata:
  annotations:
    openshift.io/node-selector: &apos;&apos;
    openshift.io/sa.scc.mcs: &apos;s0:c25,c0&apos;
    openshift.io/sa.scc.supplemental-groups: 1000600000/10000
    openshift.io/sa.scc.uid-range: 1000600000/10000
  name: ocp-etcd-backup
  labels:
    openshift.io/run-level: &apos;0&apos;
spec:
  finalizers:
    - kubernetes
EOF

oc project ocp-etcd-backup
</code></pre>
</li>
<li><p>Create config-map etcd-backup-on-debug-pod.sh from cluster-backup.sh</p>
<pre><code class="lang-bash">oc create configmap etcd-backup-on-debug-pod --from-file=etcd-backup-on-debug-pod.sh
</code></pre>
</li>
<li><p>Pickup the first master node name to run etcd backup</p>
<pre><code class="lang-bash">master_node=$(oc get node -l node-role.kubernetes.io/master= -o=jsonpath=&apos;{.items[0].metadata.name}&apos;)
</code></pre>
</li>
<li><p>Create a cronjob to run debug pod and backup script</p>
<pre><code class="lang-yaml">cat &lt;&lt; EOF | oc apply -f -
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: etcd-backup
  namespace: ocp-etcd-backup
spec:
  schedule: &apos;*/5 * * * *&apos;
  concurrencyPolicy: &quot;Replace&quot;
  startingDeadlineSeconds: 200
  jobTemplate:
    spec:
      template:
        metadata:
          labels:          
            job: &quot;etcd-backup&quot;
        spec:
          restartPolicy: Never
          activeDeadlineSeconds: 21600
          serviceAccountName: default
          hostPID: true
          priority: 0
          schedulerName: default-scheduler
          hostNetwork: true
          enableServiceLinks: true
          terminationGracePeriodSeconds: 30
          preemptionPolicy: PreemptLowerPriority
          nodeName: $master_node
          securityContext: {}
          containers:
            - resources: {}
              stdin: true
              terminationMessagePath: /dev/termination-log
              stdinOnce: true
              name: ocp-etcd-backup-pod-00
              command:
                - /scripts/etcd-backup-on-debug-pod.sh
              securityContext:
                privileged: true
                runAsUser: 0
              imagePullPolicy: IfNotPresent
              volumeMounts:
                - name: host
                  mountPath: /host
                - name: etcd-backup-script
                  mountPath: /scripts
              terminationMessagePolicy: File
              tty: true
              image: &gt;-
                quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:091cd1158444af8382312b71150d26e6550c5d52023b993fec6afd2253d2e425
          serviceAccount: default
          volumes:
            - name: host
              hostPath:
                path: /
                type: Directory
            - name: etcd-backup-script
              configMap:
                name: etcd-backup-on-debug-pod
                defaultMode: 0744
EOF
</code></pre>
</li>
</ul>
<h3 id="restoring-to-a-previous-cluster-state">Restoring to a previous cluster state</h3>
<p>To restore the cluster to a previous state, you must have previously backed up etcd data by creating a snapshot. You will use this snapshot to restore the cluster state.</p>
<p>You can use a saved etcd backup to restore back to a previous cluster state. You use the etcd backup to restore a single control plane host. Then the etcd cluster Operator handles scaling to the remaining master hosts.</p>
<p>Prerequisites</p>
<ul>
<li>Access to the cluster as a user with the cluster-admin role.</li>
<li>SSH access to master hosts.</li>
</ul>
<p>A backup directory containing both the etcd snapshot and the resources for the static pods, which were from the same backup. The file names in the directory must be in the following formats: snapshot<em><datetimestamp>.db and static_kuberesources</datetimestamp></em><datetimestamp>.tar.gz.</datetimestamp></p>
<p>Procedure</p>
<ul>
<li>Select a control plane host to use as the recovery host. This is the host that you will run the restore operation on.</li>
<li>Establish SSH connectivity to each of the control plane nodes, including the recovery host.
The Kubernetes API server becomes inaccessible after the restore process starts, so you cannot access the control plane nodes. For this reason, it is recommended to establish SSH connectivity to each control plane host in a separate terminal.
<strong>Warning:</strong> If you do not complete this step, you will not be able to access the master hosts to complete the restore procedure, and you will be unable to recover your cluster from this state.</li>
<li>Copy the etcd backup directory to the recovery control plane host.
This procedure assumes that you copied the backup directory containing the etcd snapshot and the resources for the static pods to the <code>/home/core/</code> directory of your recovery control plane host.</li>
<li><p>Stop the static pods on all other control plane nodes.
<strong>Note:</strong> It is not required to manually stop the pods on the recovery host. The recovery script will stop the pods on the recovery host.</p>
<ul>
<li>Access a control plane host that is not the recovery host.</li>
<li>Move the existing etcd pod file out of the kubelet manifest directory:<pre><code class="lang-bash">sudo mv /etc/kubernetes/manifests/etcd-pod.yaml /tmp
</code></pre>
</li>
<li><p>Verify that the etcd pods are stopped.</p>
<pre><code class="lang-bash">sudo crictl ps | grep etcd
</code></pre>
<p>The output of this command should be empty. If it is not empty, wait a few minutes and check again.</p>
</li>
<li><p>Move the existing Kubernetes API server pod file out of the kubelet manifest directory:</p>
<pre><code class="lang-bash">sudo mv /etc/kubernetes/manifests/kube-apiserver-pod.yaml /tmp
</code></pre>
</li>
<li>Verify that the Kubernetes API server pods are stopped.<pre><code class="lang-bash">sudo crictl ps | grep kube-apiserver
</code></pre>
The output of this command should be empty. If it is not empty, wait a few minutes and check again.</li>
<li>Move the etcd data directory to a different location:<pre><code class="lang-bash">sudo mv /var/lib/etcd/ /tmp
</code></pre>
</li>
<li>Repeat this step on each of the other master hosts that is not the recovery host.</li>
</ul>
</li>
<li>Access the recovery control plane host.</li>
<li>If the cluster-wide proxy is enabled, be sure that you have exported the NO_PROXY, HTTP_PROXY, and HTTPS_PROXY environment variables.
You can check whether the proxy is enabled by reviewing the output of oc get proxy cluster -o yaml. The proxy is enabled if the httpProxy, httpsProxy, and noProxy fields have values set.</li>
<li><p>Run the restore script on the recovery control plane host and pass in the path to the etcd backup directory:</p>
<pre><code class="lang-bash">sudo -E /usr/local/bin/cluster-restore.sh /home/core/backup
</code></pre>
<p>Example script output</p>
<pre><code class="lang-bash">...stopping kube-scheduler-pod.yaml
...stopping kube-controller-manager-pod.yaml
...stopping etcd-pod.yaml
...stopping kube-apiserver-pod.yaml
Waiting for container etcd to stop
.complete
Waiting for container etcdctl to stop
.............................complete
Waiting for container etcd-metrics to stop
complete
Waiting for container kube-controller-manager to stop
complete
Waiting for container kube-apiserver to stop
..........................................................................................complete
Waiting for container kube-scheduler to stop
complete
Moving etcd data-dir /var/lib/etcd/member to /var/lib/etcd-backup
starting restore-etcd static pod
starting kube-apiserver-pod.yaml
static-pod-resources/kube-apiserver-pod-7/kube-apiserver-pod.yaml
starting kube-controller-manager-pod.yaml
static-pod-resources/kube-controller-manager-pod-7/kube-controller-manager-pod.yaml
starting kube-scheduler-pod.yaml
static-pod-resources/kube-scheduler-pod-8/kube-scheduler-pod.yaml
</code></pre>
</li>
<li><p>Restart the kubelet service on all master hosts.</p>
<ul>
<li>From the recovery host, run the following command:<pre><code class="lang-bash">sudo systemctl restart kubelet.service
</code></pre>
</li>
<li>Repeat this step on all other master hosts.</li>
</ul>
</li>
<li><p>Verify that the single member control plane has started successfully.</p>
<ul>
<li><p>From the recovery host, verify that the etcd container is running.</p>
<pre><code class="lang-bash">sudo crictl ps | grep etcd
</code></pre>
<p>Example output</p>
<pre><code class="lang-bash">3ad41b7908e32       36f86e2eeaaffe662df0d21041eb22b8198e0e58abeeae8c743c3e6e977e8009                                                         About a minute ago   Running             etcd                                          0                   7c05f8af362f0
</code></pre>
</li>
<li><p>From the recovery host, verify that the etcd pod is running.</p>
<pre><code class="lang-bash">oc get pods -n openshift-etcd | grep etcd
</code></pre>
<p>Example output</p>
<pre><code class="lang-bash">NAME                                             READY   STATUS      RESTARTS   AGE
etcd-ip-10-0-143-125.ec2.internal                1/1     Running     1          2m47s
</code></pre>
<p>If the status is Pending, or the output lists more than one running etcd pod, wait a few minutes and check again.</p>
</li>
</ul>
</li>
<li><p>Force etcd redeployment.
In a terminal that has access to the cluster as a cluster-admin user, run the following command:</p>
<pre><code class="lang-bash">oc patch etcd cluster -p=&apos;{&quot;spec&quot;: {&quot;forceRedeploymentReason&quot;: &quot;recovery-&apos;&quot;$( date --rfc-3339=ns )&quot;&apos;&quot;}}&apos; --type=merge
</code></pre>
<p>The forceRedeploymentReason value must be unique, which is why a timestamp is appended.
When the etcd cluster Operator performs a redeployment, the existing nodes are started with new pods similar to the initial bootstrap scale up.</p>
</li>
<li><p>Verify all nodes are updated to the latest revision.</p>
<p>In a terminal that has access to the cluster as a cluster-admin user, run the following command:</p>
<pre><code class="lang-bash">oc get etcd -o=jsonpath=&apos;{range .items[0].status.conditions[?(@.type==&quot;NodeInstallerProgressing&quot;)]}{.reason}{&quot;\n&quot;}{.message}{&quot;\n&quot;}&apos;
</code></pre>
<p>Review the <code>NodeInstallerProgressing</code> status condition for etcd to verify that all nodes are at the latest revision. The output shows <code>AllNodesAtLatestRevision</code> upon successful update:</p>
<pre><code class="lang-bash">AllNodesAtLatestRevision
3 nodes are at revision 3
</code></pre>
<p>If the output shows a message such as 2 nodes are at revision 3; 1 nodes are at revision 4, this means that the update is still in progress. Wait a few minutes and try again.</p>
</li>
<li><p>After etcd is redeployed, force new rollouts for the control plane. The Kubernetes API server will reinstall itself on the other nodes because the kubelet is connected to API servers using an internal load balancer.</p>
</li>
</ul>
<p>In a terminal that has access to the cluster as a cluster-admin user, run the following commands.</p>
<ul>
<li><p>Update the kubeapiserver:</p>
<pre><code class="lang-bash">oc patch kubeapiserver cluster -p=&apos;{&quot;spec&quot;: {&quot;forceRedeploymentReason&quot;: &quot;recovery-&apos;&quot;$( date --rfc-3339=ns )&quot;&apos;&quot;}}&apos; --type=merge
</code></pre>
<p>Verify all nodes are updated to the latest revision.</p>
<pre><code class="lang-bash">oc get kubeapiserver -o=jsonpath=&apos;{range .items[0].status.conditions[?(@.type==&quot;NodeInstallerProgressing&quot;)]}{.reason}{&quot;\n&quot;}{.message}{&quot;\n&quot;}&apos;
</code></pre>
<p>Review the <code>NodeInstallerProgressing</code> status condition to verify that all nodes are at the latest revision. The output shows <code>AllNodesAtLatestRevision</code> upon successful update:</p>
<pre><code class="lang-bash">AllNodesAtLatestRevision
3 nodes are at revision 3
</code></pre>
</li>
<li><p>Update the kubecontrollermanager:</p>
<pre><code class="lang-bash">oc patch kubecontrollermanager cluster -p=&apos;{&quot;spec&quot;: {&quot;forceRedeploymentReason&quot;: &quot;recovery-&apos;&quot;$( date --rfc-3339=ns )&quot;&apos;&quot;}}&apos; --type=merge
</code></pre>
<p>Verify all nodes are updated to the latest revision.</p>
<pre><code class="lang-bash">oc get kubecontrollermanager -o=jsonpath=&apos;{range .items[0].status.conditions[?(@.type==&quot;NodeInstallerProgressing&quot;)]}{.reason}{&quot;\n&quot;}{.message}{&quot;\n&quot;}&apos;
</code></pre>
<p>Review the <code>NodeInstallerProgressing</code> status condition to verify that all nodes are at the latest revision. The output shows <code>AllNodesAtLatestRevision</code> upon successful update:</p>
<pre><code class="lang-bash">AllNodesAtLatestRevision
3 nodes are at revision 3
</code></pre>
</li>
<li><p>Update the kubescheduler:</p>
<pre><code class="lang-bash">oc patch kubescheduler cluster -p=&apos;{&quot;spec&quot;: {&quot;forceRedeploymentReason&quot;: &quot;recovery-&apos;&quot;$( date --rfc-3339=ns )&quot;&apos;&quot;}}&apos; --type=merge
</code></pre>
<p>Verify all nodes are updated to the latest revision.</p>
<pre><code class="lang-bash">oc get kubescheduler -o=jsonpath=&apos;{range .items[0].status.conditions[?(@.type==&quot;NodeInstallerProgressing&quot;)]}{.reason}{&quot;\n&quot;}{.message}{&quot;\n&quot;}&apos;
</code></pre>
<p>Review the <code>NodeInstallerProgressing</code> status condition to verify that all nodes are at the latest revision. The output shows <code>AllNodesAtLatestRevision</code> upon successful update:</p>
<pre><code class="lang-bash">AllNodesAtLatestRevision
3 nodes are at revision 3
</code></pre>
</li>
</ul>
<ul>
<li><p>Verify that all master hosts have started and joined the cluster.</p>
<p>In a terminal that has access to the cluster as a cluster-admin user, run the following command:</p>
<pre><code class="lang-bash">oc get pods -n openshift-etcd | grep etcd
</code></pre>
<p>Example output</p>
<pre><code class="lang-bash">etcd-ip-10-0-143-125.ec2.internal                2/2     Running     0          9h
etcd-ip-10-0-154-194.ec2.internal                2/2     Running     0          9h
etcd-ip-10-0-173-171.ec2.internal                2/2     Running     0          9h
</code></pre>
</li>
</ul>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="infrastructure-networking.html" class="navigation navigation-prev " aria-label="Previous page: OpenShift Networking">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="infrastructure-taint-and-toleration.html" class="navigation navigation-next " aria-label="Next page: Pod Taint and Toleration">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"OpenShift state backup with etcd snapshot","level":"1.2.6","depth":2,"next":{"title":"Pod Taint and Toleration","level":"1.2.7","depth":2,"path":"infrastructure-taint-and-toleration.md","ref":"infrastructure-taint-and-toleration.md","articles":[]},"previous":{"title":"OpenShift Networking","level":"1.2.5","depth":2,"path":"infrastructure-networking.md","ref":"infrastructure-networking.md","articles":[]},"dir":"ltr"},"config":{"plugins":["-lunr","-search","-highlight","-livereload","search-plus","copy-code-button","mermaid-gb3"],"root":"./","styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"mermaid-newface":{"theme":"neutral"},"search-plus":{},"copy-code-button":{},"mermaid-gb3":{},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","author":"Red Hat Thailand SA","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"OpenShift Demo","gitbook":"3.2.3"},"file":{"path":"infrastructure-backup-etcd.md","mtime":"2022-10-25T06:15:22.292Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2022-10-25T06:16:12.052Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-search-plus/jquery.mark.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search-plus/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-copy-code-button/toggle.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-mermaid-gb3/book/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    <script src="gitbook/gitbook-plugin-mermaid-gb3/mermaid/mermaid.min.js"></script>

    </body>
</html>

